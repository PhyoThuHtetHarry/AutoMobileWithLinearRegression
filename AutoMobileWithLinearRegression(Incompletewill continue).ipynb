{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "import sklearn.model_selection as ms\n",
    "from sklearn import linear_model\n",
    "import sklearn.metrics as sklm\n",
    "import numpy as np\n",
    "import numpy.random as nr\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import scipy.stats as ss\n",
    "import math\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['symboling', 'make', 'fuel_type', 'aspiration', 'num_of_doors',\n",
       "       'body_style', 'drive_wheels', 'engine_location', 'wheel_base', 'length',\n",
       "       'width', 'height', 'curb_weight', 'engine_type', 'num_of_cylinders',\n",
       "       'engine_size', 'fuel_system', 'bore', 'stroke', 'compression_ratio',\n",
       "       'horsepower', 'peak_rpm', 'city_mpg', 'highway_mpg', 'price',\n",
       "       'log_price'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "auto_prices = pd.read_csv('Auto_Data_Preped.csv')\n",
    "auto_prices.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>symboling</th>\n",
       "      <th>make</th>\n",
       "      <th>fuel_type</th>\n",
       "      <th>aspiration</th>\n",
       "      <th>num_of_doors</th>\n",
       "      <th>body_style</th>\n",
       "      <th>drive_wheels</th>\n",
       "      <th>engine_location</th>\n",
       "      <th>wheel_base</th>\n",
       "      <th>length</th>\n",
       "      <th>...</th>\n",
       "      <th>fuel_system</th>\n",
       "      <th>bore</th>\n",
       "      <th>stroke</th>\n",
       "      <th>compression_ratio</th>\n",
       "      <th>horsepower</th>\n",
       "      <th>peak_rpm</th>\n",
       "      <th>city_mpg</th>\n",
       "      <th>highway_mpg</th>\n",
       "      <th>price</th>\n",
       "      <th>log_price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>alfa-romero</td>\n",
       "      <td>gas</td>\n",
       "      <td>std</td>\n",
       "      <td>two</td>\n",
       "      <td>hardtop_convert</td>\n",
       "      <td>rwd</td>\n",
       "      <td>front</td>\n",
       "      <td>88.6</td>\n",
       "      <td>168.8</td>\n",
       "      <td>...</td>\n",
       "      <td>mpfi</td>\n",
       "      <td>3.47</td>\n",
       "      <td>2.68</td>\n",
       "      <td>9.0</td>\n",
       "      <td>111</td>\n",
       "      <td>5000</td>\n",
       "      <td>21</td>\n",
       "      <td>27</td>\n",
       "      <td>13495</td>\n",
       "      <td>9.510075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>alfa-romero</td>\n",
       "      <td>gas</td>\n",
       "      <td>std</td>\n",
       "      <td>two</td>\n",
       "      <td>hardtop_convert</td>\n",
       "      <td>rwd</td>\n",
       "      <td>front</td>\n",
       "      <td>88.6</td>\n",
       "      <td>168.8</td>\n",
       "      <td>...</td>\n",
       "      <td>mpfi</td>\n",
       "      <td>3.47</td>\n",
       "      <td>2.68</td>\n",
       "      <td>9.0</td>\n",
       "      <td>111</td>\n",
       "      <td>5000</td>\n",
       "      <td>21</td>\n",
       "      <td>27</td>\n",
       "      <td>16500</td>\n",
       "      <td>9.711116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>alfa-romero</td>\n",
       "      <td>gas</td>\n",
       "      <td>std</td>\n",
       "      <td>two</td>\n",
       "      <td>hatchback</td>\n",
       "      <td>rwd</td>\n",
       "      <td>front</td>\n",
       "      <td>94.5</td>\n",
       "      <td>171.2</td>\n",
       "      <td>...</td>\n",
       "      <td>mpfi</td>\n",
       "      <td>2.68</td>\n",
       "      <td>3.47</td>\n",
       "      <td>9.0</td>\n",
       "      <td>154</td>\n",
       "      <td>5000</td>\n",
       "      <td>19</td>\n",
       "      <td>26</td>\n",
       "      <td>16500</td>\n",
       "      <td>9.711116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>audi</td>\n",
       "      <td>gas</td>\n",
       "      <td>std</td>\n",
       "      <td>four</td>\n",
       "      <td>sedan</td>\n",
       "      <td>fwd</td>\n",
       "      <td>front</td>\n",
       "      <td>99.8</td>\n",
       "      <td>176.6</td>\n",
       "      <td>...</td>\n",
       "      <td>mpfi</td>\n",
       "      <td>3.19</td>\n",
       "      <td>3.40</td>\n",
       "      <td>10.0</td>\n",
       "      <td>102</td>\n",
       "      <td>5500</td>\n",
       "      <td>24</td>\n",
       "      <td>30</td>\n",
       "      <td>13950</td>\n",
       "      <td>9.543235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>audi</td>\n",
       "      <td>gas</td>\n",
       "      <td>std</td>\n",
       "      <td>four</td>\n",
       "      <td>sedan</td>\n",
       "      <td>4wd</td>\n",
       "      <td>front</td>\n",
       "      <td>99.4</td>\n",
       "      <td>176.6</td>\n",
       "      <td>...</td>\n",
       "      <td>mpfi</td>\n",
       "      <td>3.19</td>\n",
       "      <td>3.40</td>\n",
       "      <td>8.0</td>\n",
       "      <td>115</td>\n",
       "      <td>5500</td>\n",
       "      <td>18</td>\n",
       "      <td>22</td>\n",
       "      <td>17450</td>\n",
       "      <td>9.767095</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   symboling         make fuel_type aspiration num_of_doors       body_style  \\\n",
       "0          3  alfa-romero       gas        std          two  hardtop_convert   \n",
       "1          3  alfa-romero       gas        std          two  hardtop_convert   \n",
       "2          1  alfa-romero       gas        std          two        hatchback   \n",
       "3          2         audi       gas        std         four            sedan   \n",
       "4          2         audi       gas        std         four            sedan   \n",
       "\n",
       "  drive_wheels engine_location  wheel_base  length    ...      fuel_system  \\\n",
       "0          rwd           front        88.6   168.8    ...             mpfi   \n",
       "1          rwd           front        88.6   168.8    ...             mpfi   \n",
       "2          rwd           front        94.5   171.2    ...             mpfi   \n",
       "3          fwd           front        99.8   176.6    ...             mpfi   \n",
       "4          4wd           front        99.4   176.6    ...             mpfi   \n",
       "\n",
       "   bore  stroke compression_ratio horsepower  peak_rpm city_mpg  highway_mpg  \\\n",
       "0  3.47    2.68               9.0        111      5000       21           27   \n",
       "1  3.47    2.68               9.0        111      5000       21           27   \n",
       "2  2.68    3.47               9.0        154      5000       19           26   \n",
       "3  3.19    3.40              10.0        102      5500       24           30   \n",
       "4  3.19    3.40               8.0        115      5500       18           22   \n",
       "\n",
       "   price  log_price  \n",
       "0  13495   9.510075  \n",
       "1  16500   9.711116  \n",
       "2  16500   9.711116  \n",
       "3  13950   9.543235  \n",
       "4  17450   9.767095  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "auto_prices.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare the model matrix.\n",
    "1. All scikit-learn models require a numpy array of numeric only values for the features. \n",
    "   The resulting array is often referred to as the model matrix. \n",
    "\n",
    "2. To create a model matrix from cases with both numeric and categorical variables requires two steps. First, the numeric   \n",
    "   features must be rescaled. Second, the categorical variables must be converted to a set of dummy variables to encode the \n",
    "   presence or not of each category. \n",
    "\n",
    "3. Create dummy variables from categorical features\n",
    "   Now, you must create dummy variables for the categorical features. Dummy variables encode categorical features as a set of  \n",
    "   binary variables. There is one dummy variable for each possible category. For each case all of the values in the dummy \n",
    "   variables are set to zero, except the one corresponding to the category value, which is set to one. In this way, a \n",
    "   categorical variable with any number of categories can be encoded as series of numeric features which scikit-learn can \n",
    "   operate on. This process is referred to as one hot encoding since only one dummy variable is coded as 1 (hot) per case. \n",
    "\n",
    "4. The sklearn.preprocessing package contains functions to encode categorical features as dummy variables in two steps;\n",
    "   The categories are encoded as numbers starting with 0. For example, if there are 5 categories, they are encoded as the set \n",
    "   {0,1,2,3,4}\n",
    "   {0,1,2,3,4}\n",
    ".  The numeric categories are then encoded as dummy variables. \n",
    "   The following example will give you a feel for how this process works. The code in the cell below computes the numeric  \n",
    "   representation of the categories for the body_style feature by the following steps:\n",
    "   An encoder object is created using the LabelEncoder method.\n",
    "   The encoder is fit to the unique string values of the feature. \n",
    "   The transformation method then applies the numeric encoding to the original feature. \n",
    "   Execute the code in the cell below and examine the result. \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['hardtop_convert' 'hatchback' 'sedan' 'wagon']\n",
      "[0 0 1 2 2 2 2 3 2 2 2 2 2 2 2 2 2 1 1 2 1 1 1 1 2 2 2 3 1 1 1 1 1 1 2 3 1\n",
      " 1 2 2 2 2 2 1 2 2 2 1 1 1 2 2 1 2 1 2 2 1 2 2 2 3 0 2 2 0 2 0 1 1 1 1 1 1\n",
      " 1 1 1 1 2 2 2 2 2 2 2 2 3 2 1 2 3 0 1 2 2 3 2 1 1 1 2 2 3 3 2 2 3 3 2 2 2\n",
      " 1 1 1 2 2 3 1 1 0 0 0 1 2 1 2 1 2 1 1 1 2 2 2 2 2 3 3 3 3 1 1 1 3 3 3 2 1\n",
      " 2 1 2 1 2 2 1 2 1 0 0 1 0 1 0 2 2 1 2 1 1 1 2 3 2 2 2 2 2 2 2 0 1 2 2 3 2\n",
      " 3 2 3 2 3 2 2 2 2 2]\n"
     ]
    }
   ],
   "source": [
    "print(auto_prices['body_style'].unique())\n",
    "Features = auto_prices['body_style']\n",
    "enc      = preprocessing.LabelEncoder()\n",
    "enc.fit(Features)\n",
    "Features = enc.transform(Features)\n",
    "print(Features)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that this five original body style categories of this feature is now coded as integers in the set \n",
    "{0,1,2,3,4}\n",
    "{0,1,2,3,4}\n",
    ".\n",
    "For the next step in the process, the numerically coded categorical variable is converted to a set of dummy variables following these steps:\n",
    "\n",
    "A one hot encoder object is created using the OneHotEncoder method from the sklearn.preprocessing module.\n",
    "The numerically coded categorical feature is fit with the one hot encoder. \n",
    "The dummy variables are encoded using the transform method on the encodings.\n",
    "Execute the code in the cell below and examine the result. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.,  0.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.,  0.],\n",
       "       [ 0.,  1.,  0.,  0.],\n",
       "       [ 0.,  0.,  1.,  0.],\n",
       "       [ 0.,  0.,  1.,  0.],\n",
       "       [ 0.,  0.,  1.,  0.],\n",
       "       [ 0.,  0.,  1.,  0.],\n",
       "       [ 0.,  0.,  0.,  1.],\n",
       "       [ 0.,  0.,  1.,  0.],\n",
       "       [ 0.,  0.,  1.,  0.]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ohe = preprocessing.OneHotEncoder()\n",
    "encoded = ohe.fit(Features.reshape(-1,1))#feature.reshape is for changing rows to cols\n",
    "Features = encoded.transform(Features.reshape(-1,1)).toarray()\n",
    "Features[:10,:]# To check Later"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the body_style feature has been encoded as five columns.\n",
    "Each of these columns is a dummy variable representing one category. \n",
    "Each row has one and only one dummy variable with a 1, and the rest 0s. \n",
    "This is the one hot encoding.\n",
    "\n",
    "Now, you need to one hot encode all five categorical variables and append them as columns to the model matrix with the scaled numeric variables. The code in the cell below executes a for loop that calls the encode_string function and uses the numpy concatenate function to add the dummy variables to the model matrix. The encode_string function uses the same process discussed above. \n",
    "Execute this code, verify the result, and answer Question 1 on the course page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(195, 14)\n",
      "[[ 1.  0.  0.  0.  0.  1.  1.  0.  0.  0.  1.  0.  0.  1.]\n",
      " [ 1.  0.  0.  0.  0.  1.  1.  0.  0.  0.  1.  0.  0.  1.]]\n"
     ]
    }
   ],
   "source": [
    "def encode_string(cat_feature):\n",
    "    ## First encode the strings to numeric categories\n",
    "    enc = preprocessing.LabelEncoder()\n",
    "    enc.fit(cat_feature)\n",
    "    enc_cat_feature = enc.transform(cat_feature)\n",
    "    ## Now, apply one hot encoding\n",
    "    ohe = preprocessing.OneHotEncoder()\n",
    "    encoded = ohe.fit(enc_cat_feature.reshape(-1,1))\n",
    "    return encoded.transform(enc_cat_feature.reshape(-1,1)).toarray()\n",
    "    \n",
    "\n",
    "categorical_columns = ['fuel_type', 'aspiration', 'drive_wheels', 'num_of_cylinders']\n",
    "\n",
    "for col in categorical_columns:\n",
    "    temp = encode_string(auto_prices[col])\n",
    "    Features = np.concatenate([Features, temp], axis = 1)\n",
    "\n",
    "print(Features.shape)\n",
    "print(Features[:2, :])       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "195\n"
     ]
    }
   ],
   "source": [
    "Features = np.concatenate([Features,np.array(auto_prices[['curb_weight','horsepower','city_mpg']])],axis = 1)\n",
    "Features[:2,:]\n",
    "print(Features.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "nr.seed(9988)\n",
    "labels = np.array(auto_prices['log_price'])\n",
    "indx = range(Features.shape[0])\n",
    "indx = ms.train_test_split(indx,test_size =40)\n",
    "\n",
    "x_train = Features[indx[0],:]\n",
    "y_train = np.ravel(labels[indx[0]])\n",
    "x_test = Features[indx[1],:]\n",
    "y_test = np.ravel(labels[indx[1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rescale numeric features\n",
    "Numeric features must be rescaled so they have a similar range of values. Rescaling prevents features from having an undue influence on model training simply because then have a larger range of numeric variables. \n",
    "The code in the cell below uses the StandardScaler function from the Scikit Learn preprocessing package to Zscore scale the numeric features. Notice that the scaler is fit only on the training data. The trained scaler is these applied to the test data. Test data should always be scaled using the parameters from the training data. \n",
    "Execute this code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(155, 35)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0.        ,  0.        ,  1.        ,  0.        ,  1.        ,\n",
       "         0.        ,  1.        ,  0.        ,  0.        ,  1.        ,\n",
       "         0.        ,  0.        ,  0.        ,  1.        , -0.5384069 ,\n",
       "        -1.26225437,  1.33602998, -0.5384069 , -1.26225437,  1.33602998,\n",
       "        -0.5384069 , -1.26225437,  1.33602998, -0.5384069 , -1.26225437,\n",
       "         1.33602998, -0.5384069 , -1.26225437,  1.33602998, -0.5384069 ,\n",
       "        -1.26225437,  1.33602998, -0.5384069 , -1.26225437,  1.33602998],\n",
       "       [ 0.        ,  0.        ,  1.        ,  0.        ,  0.        ,\n",
       "         1.        ,  0.        ,  1.        ,  0.        ,  0.        ,\n",
       "         1.        ,  0.        ,  0.        ,  1.        ,  0.96837381,\n",
       "         1.51064566, -1.00126852,  0.96837381,  1.51064566, -1.00126852,\n",
       "         0.96837381,  1.51064566, -1.00126852,  0.96837381,  1.51064566,\n",
       "        -1.00126852,  0.96837381,  1.51064566, -1.00126852,  0.96837381,\n",
       "         1.51064566, -1.00126852,  0.96837381,  1.51064566, -1.00126852],\n",
       "       [ 0.        ,  1.        ,  0.        ,  0.        ,  0.        ,\n",
       "         1.        ,  1.        ,  0.        ,  0.        ,  1.        ,\n",
       "         0.        ,  0.        ,  0.        ,  1.        , -0.86156658,\n",
       "        -0.88897936,  0.71275038, -0.86156658, -0.88897936,  0.71275038,\n",
       "        -0.86156658, -0.88897936,  0.71275038, -0.86156658, -0.88897936,\n",
       "         0.71275038, -0.86156658, -0.88897936,  0.71275038, -0.86156658,\n",
       "        -0.88897936,  0.71275038, -0.86156658, -0.88897936,  0.71275038],\n",
       "       [ 0.        ,  0.        ,  1.        ,  0.        ,  0.        ,\n",
       "         1.        ,  1.        ,  0.        ,  0.        ,  1.        ,\n",
       "         0.        ,  0.        ,  0.        ,  1.        , -0.27559631,\n",
       "        -0.51570436,  0.08947078, -0.27559631, -0.51570436,  0.08947078,\n",
       "        -0.27559631, -0.51570436,  0.08947078, -0.27559631, -0.51570436,\n",
       "         0.08947078, -0.27559631, -0.51570436,  0.08947078, -0.27559631,\n",
       "        -0.51570436,  0.08947078, -0.27559631, -0.51570436,  0.08947078],\n",
       "       [ 0.        ,  0.        ,  1.        ,  0.        ,  0.        ,\n",
       "         1.        ,  0.        ,  1.        ,  0.        ,  0.        ,\n",
       "         1.        ,  0.        ,  0.        ,  1.        ,  0.9936815 ,\n",
       "         0.28417065, -1.00126852,  0.9936815 ,  0.28417065, -1.00126852,\n",
       "         0.9936815 ,  0.28417065, -1.00126852,  0.9936815 ,  0.28417065,\n",
       "        -1.00126852,  0.9936815 ,  0.28417065, -1.00126852,  0.9936815 ,\n",
       "         0.28417065, -1.00126852,  0.9936815 ,  0.28417065, -1.00126852]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler = preprocessing.StandardScaler().fit(x_train[:,14:])\n",
    "x_train[:,14:] = scaler.transform(x_train[:,14:])\n",
    "x_test[:,14:] = scaler.transform(x_test[:,14:])\n",
    "print(x_train.shape)\n",
    "x_train[:5,:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=False, n_jobs=1, normalize=False)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lin_mod = linear_model.LinearRegression(fit_intercept = False)\n",
    "lin_mod.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "[ 1.36372345  1.15436725  1.27397827  1.16791069  2.57778903  2.38219063\n",
      "  2.48184692  2.47813274  1.62299441  1.62646566  1.71051959  1.70397511\n",
      "  1.71596353  1.54004103  0.02572832  0.02021161 -0.01042417  0.02572832\n",
      "  0.02021161 -0.01042417  0.02572832  0.02021161 -0.01042417  0.02572832\n",
      "  0.02021161 -0.01042417  0.02572832  0.02021161 -0.01042417  0.02572832\n",
      "  0.02021161 -0.01042417  0.02572832  0.02021161 -0.01042417]\n"
     ]
    }
   ],
   "source": [
    "print(lin_mod.intercept_)\n",
    "print(lin_mod.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Square Error      = 0.0226162077444\n",
      "Root Mean Square Error = 0.1503868602784332\n",
      "Mean Absolute Error    = 0.119126784368\n",
      "Median Absolute Error  = 0.106964494329\n",
      "R^2                    = 0.921638632103\n",
      "Adjusted R^2           = 0.745325554333\n"
     ]
    }
   ],
   "source": [
    "def print_metrics(y_true, y_predicted, n_parameters):\n",
    "    ## First compute R^2 and the adjusted R^2\n",
    "    r2 = sklm.r2_score(y_true, y_predicted)\n",
    "    r2_adj = r2 - (n_parameters - 1)/(y_true.shape[0] - n_parameters) * (1 - r2)\n",
    "    \n",
    "    ## Print the usual metrics and the R^2 values\n",
    "    print('Mean Square Error      = ' + str(sklm.mean_squared_error(y_true, y_predicted)))\n",
    "    print('Root Mean Square Error = ' + str(math.sqrt(sklm.mean_squared_error(y_true, y_predicted))))\n",
    "    print('Mean Absolute Error    = ' + str(sklm.mean_absolute_error(y_true, y_predicted)))\n",
    "    print('Median Absolute Error  = ' + str(sklm.median_absolute_error(y_true, y_predicted)))\n",
    "    print('R^2                    = ' + str(r2))\n",
    "    print('Adjusted R^2           = ' + str(r2_adj))\n",
    "   \n",
    "y_score = lin_mod.predict(x_test) \n",
    "print_metrics(y_test, y_score, 28)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
